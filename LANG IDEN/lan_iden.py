# -*- coding: utf-8 -*-
"""lan iden.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iOYa9KKVgpODPX08Falm3c3yNu7OntVA
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv('/content/dataset.csv')

data.head()

data.shape

data['language'].value_counts()

plt.figure(figsize=(20,20))
sns.countplot(data['language'])

data['Text'][345]

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import re

nltk.download('stopwords')

ps = PorterStemmer()

rev = "This is a sample review containing some words that we want to filter and stem."

filtered_rev = [ps.stem(word) for word in rev.split() if word not in stopwords.words('english')]
print(filtered_rev)

ps = PorterStemmer()
corpus=[]

for i in range(len(data['Text'])):

  rev = re.sub("^[a-zA-Z]",' ',data['Text'][i])
  rev = rev.lower()
  rev = rev.split()
  rev = [ps.stem(word) for word in rev if set(stopwords.words())]
  rev = ' '.join(rev)
  corpus.append(rev)

  print(f"{i}")

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=1000)
X = cv.fit_transform(corpus).toarray()

X.shape

from sklearn.preprocessing import LabelEncoder
label = LabelEncoder()
y = label.fit_transform(data['language'])

y

len(y)

label.classes_

data1 = pd.DataFrame(np.c_[corpus,y],columns=['Sentence','Language'])

data1

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.naive_bayes import MultinomialNB

classifier = MultinomialNB().fit(X_train,y_train)

pred = classifier.predict(X_test)

pred

y_test

from sklearn.metrics import accuracy_score,confusion_matrix
print(accuracy_score(y_test,pred))
print(confusion_matrix(y_test,pred))

plt.figure(figsize=(20,20))
sns.heatmap(confusion_matrix(y_test,pred),annot=True,cmap=plt.cm.Accent)

fnl = pd.DataFrame(np.c_[y_test,pred],columns=['Actual','predicted'])
fnl

import joblib
joblib.dump(classifier,'language_identification.sav')

model=joblib.load('language_identification.sav')

def test_model(test_sentence):
    languages = {
    'Arabic': 0,
    'Chinese': 1,
    'Dutch' : 2,
    'English': 3,
    'Estonian': 4,
    'French': 5,
    'Hindi': 6,
    'Indonesian' : 7,
    'Japanese' : 8,
    'Korean': 9,
    'Latin': 10,
    'Persian': 11,
    'Portugese' : 12,
    'Pushto': 13,
    'Romanian': 14,
    'Russian':15,
    'Spanish': 16,
    'Swedish': 17,
    'Tamil': 18,
    'Thai': 19,
    'Turkish' : 20,
    'Urdu' : 21
    }

    rev = re.sub('^[a-zA-Z]',' ',test_sentence)
    rev =  rev.lower()
    rev = rev.split()
    rev = [ps.stem(word) for word in rev if word not in set(stopwords.words())]
    rev = ' '.join(rev)

    rev = cv.transform([rev]).toarray()
    output = model.predict(rev)[0]

    keys = list(languages)
    values = list(languages.values())
    position = values.index(output)

    output = keys[position]
    print(output)

test_model('को मरं मांक')

test_model('พวกเราเป็นเด็กดี')

test_model('in quo habitas')

pd.DataFrame(np.c_[data['Text'], data['language'], y], columns=['sentence', 'Language', 'Encoded'])

import pickle
file = open('CountVectorizer.pkl', 'wb')
pickle.dump(cv, file)

